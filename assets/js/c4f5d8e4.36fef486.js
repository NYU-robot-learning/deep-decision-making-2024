"use strict";(self.webpackChunkdeep_rl_2024=self.webpackChunkdeep_rl_2024||[]).push([[195],{9600:(e,i,s)=>{s.r(i),s.d(i,{default:()=>h});var a=s(2263),t=s(6040),r=(s(7294),s(3692)),n=s(4996),o=(s(9286),s(512));const l={features:"features_t9lD",featureSvg:"featureSvg_GfXr"};var d=s(5893);const c=function(){const e=(0,a.Z)(),{siteConfig:i={}}=e;return(0,d.jsxs)(t.Z,{permalink:"/",description:"Set up a modern web app by running one command.",children:[(0,d.jsx)("div",{className:(0,o.Z)("hero hero--dark",l.heroBanner),children:(0,d.jsxs)("div",{className:"container",children:[(0,d.jsx)("video",{className:(0,o.Z)(l.heroBannerLogo,"margin-vert--md","fit-width"),autostart:!0,autoPlay:!0,loop:!0,muted:!0,alt:"ML",src:(0,n.Z)("img/ML.mp4"),type:"video/mp4"}),(0,d.jsx)("video",{className:(0,o.Z)(l.heroBannerLogo,"margin-vert--md","fit-width"),autostart:!0,autoPlay:!0,loop:!0,muted:!0,alt:"DL",src:(0,n.Z)("img/DL.mp4"),type:"video/mp4"}),(0,d.jsx)("video",{className:(0,o.Z)(l.heroBannerLogo,"margin-vert--md","fit-width"),autostart:!0,autoPlay:!0,loop:!0,muted:!0,alt:"RL",src:(0,n.Z)("img/RL.mp4"),type:"video/mp4"}),(0,d.jsx)("h1",{className:"hero__title",children:i.title}),(0,d.jsx)("p",{className:"hero__subtitle",children:i.tagline}),(0,d.jsx)("div",{className:l.getStarted,children:(0,d.jsx)(r.Z,{className:"button button--outline button--primary button--lg",to:(0,n.Z)("docs/logistics"),children:"Get Started"})})]})}),(0,d.jsx)("div",{className:l.features,children:(0,d.jsx)("div",{className:"container",children:(0,d.jsx)("div",{className:"row",children:(0,d.jsxs)("div",{className:"col col--12",children:[(0,d.jsx)("h2",{children:"Overview"}),(0,d.jsx)("p",{children:"Deep Reinforcement Learning (RL) has made massive strides in the last decade for sequential decision making problems such as playing Atari games, mastering GO, and continuous control of robots. This course serves as a graduate-level introduction to RL, with an emphasis on applications and recent research. Students will be introduced to a broad set of topics in RL: Basic formalisms; Exploration vs exploitation; Imitation learning; Model-free RL; Model-based control and planning; Unsupervised learning for RL; Applications to games, robotics, industry; Current frontiers. This course will involve several coding home-works where you will implement various algorithms, and a final project. Other alternative titles for this course are Adaptive control and learning, Dynamic optimization."}),(0,d.jsx)("p",{children:"This class is modeled on previous offerings from Spring 2022 and Fall 2021. Building on the traditions of these previous offerings, this version of the class will place a larger emphasis on practical, hands-on experience with building ML algorithms. To broaded the scope of this offering, we will add lectures on self-supervised learning and reinforcement learning."})]})})})}),(0,d.jsx)("div",{className:l.gettingStartedSection,children:(0,d.jsxs)("div",{className:"container padding-vert--xl text--left",children:[(0,d.jsx)("h2",{children:"Staff"}),(0,d.jsxs)("div",{className:"row",children:[(0,d.jsxs)("div",{className:"col col--3",children:[(0,d.jsx)("h3",{children:(0,d.jsx)("a",{href:"https://www.lerrelpinto.com/",children:"Lerrel Pinto"})}),(0,d.jsx)("img",{className:l.featureImage,alt:"Lerrel Pinto",src:(0,n.Z)("img/lerrel.jpeg")})]}),(0,d.jsxs)("div",{className:"col col--3 col--offset-3",children:[(0,d.jsx)("h3",{children:(0,d.jsx)("a",{href:"https://siddhanthaldar.github.io/",children:"Siddhant Haldar"})}),(0,d.jsx)("img",{className:l.featureImage,alt:"Siddhant Haldar",src:(0,n.Z)("img/siddhant.jpg")})]})]})]})})]})};function h(){const{siteConfig:e}=(0,a.Z)();return(0,d.jsx)(t.Z,{title:`${e.title}`,description:"Description will go into a meta tag in <head />",children:(0,d.jsx)("main",{children:(0,d.jsx)(c,{})})})}}}]);